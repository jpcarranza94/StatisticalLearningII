{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project: Recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this specific task we will be using a recurrent neural network to create a model to classify 60,000 Stack Overflow Questions, each with a quality score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34552656</td>\n",
       "      <td>Java: Repeat Task Every Random Seconds</td>\n",
       "      <td>&lt;p&gt;I'm already familiar with repeating tasks e...</td>\n",
       "      <td>&lt;java&gt;&lt;repeat&gt;</td>\n",
       "      <td>2016-01-01 00:21:59</td>\n",
       "      <td>LQ_CLOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34552974</td>\n",
       "      <td>How to get all the child records from differen...</td>\n",
       "      <td>I am having 4 different tables like \\r\\nselect...</td>\n",
       "      <td>&lt;sql&gt;&lt;sql-server&gt;</td>\n",
       "      <td>2016-01-01 01:44:52</td>\n",
       "      <td>LQ_EDIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34553034</td>\n",
       "      <td>Why are Java Optionals immutable?</td>\n",
       "      <td>&lt;p&gt;I'd like to understand why Java 8 Optionals...</td>\n",
       "      <td>&lt;java&gt;&lt;optional&gt;</td>\n",
       "      <td>2016-01-01 02:03:20</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34553174</td>\n",
       "      <td>Text Overlay Image with Darkened Opacity React...</td>\n",
       "      <td>&lt;p&gt;I am attempting to overlay a title over an ...</td>\n",
       "      <td>&lt;javascript&gt;&lt;image&gt;&lt;overlay&gt;&lt;react-native&gt;&lt;opa...</td>\n",
       "      <td>2016-01-01 02:48:24</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34553318</td>\n",
       "      <td>Why ternary operator in swift is so picky?</td>\n",
       "      <td>&lt;p&gt;The question is very simple, but I just cou...</td>\n",
       "      <td>&lt;swift&gt;&lt;operators&gt;&lt;whitespace&gt;&lt;ternary-operato...</td>\n",
       "      <td>2016-01-01 03:30:17</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  34552656             Java: Repeat Task Every Random Seconds   \n",
       "1  34552974  How to get all the child records from differen...   \n",
       "2  34553034                  Why are Java Optionals immutable?   \n",
       "3  34553174  Text Overlay Image with Darkened Opacity React...   \n",
       "4  34553318         Why ternary operator in swift is so picky?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'm already familiar with repeating tasks e...   \n",
       "1  I am having 4 different tables like \\r\\nselect...   \n",
       "2  <p>I'd like to understand why Java 8 Optionals...   \n",
       "3  <p>I am attempting to overlay a title over an ...   \n",
       "4  <p>The question is very simple, but I just cou...   \n",
       "\n",
       "                                                Tags         CreationDate  \\\n",
       "0                                     <java><repeat>  2016-01-01 00:21:59   \n",
       "1                                  <sql><sql-server>  2016-01-01 01:44:52   \n",
       "2                                   <java><optional>  2016-01-01 02:03:20   \n",
       "3  <javascript><image><overlay><react-native><opa...  2016-01-01 02:48:24   \n",
       "4  <swift><operators><whitespace><ternary-operato...  2016-01-01 03:30:17   \n",
       "\n",
       "          Y  \n",
       "0  LQ_CLOSE  \n",
       "1   LQ_EDIT  \n",
       "2        HQ  \n",
       "3        HQ  \n",
       "4        HQ  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Id            60000 non-null  int64 \n",
      " 1   Title         60000 non-null  object\n",
      " 2   Body          60000 non-null  object\n",
      " 3   Tags          60000 non-null  object\n",
      " 4   CreationDate  60000 non-null  object\n",
      " 5   Y             60000 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse text from html file using BeautifulSoup\n",
    "df.Body = df.Body.apply(lambda x: BeautifulSoup(x, 'html.parser').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        I'm already familiar with repeating tasks ever...\n",
       "1        I am having 4 different tables like \\r\\nselect...\n",
       "2        I'd like to understand why Java 8 Optionals we...\n",
       "3        I am attempting to overlay a title over an ima...\n",
       "4        The question is very simple, but I just could ...\n",
       "                               ...                        \n",
       "59995    I try to multiply an integer by a double but I...\n",
       "59996    I'm very new to programming and I'm teaching m...\n",
       "59997        *URLS.PY*\\r\\n    //URLS.PY FILE\\r\\n    fro...\n",
       "59998    I have a controller inside which a server is c...\n",
       "59999    So i was recently helping someone out with som...\n",
       "Name: Body, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a final text file is created that inclused both the title and the body of the Stack Overflow question\n",
    "df['text'] = df['Title'] + \" \" + df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_sizes = np.array([len(i.split()) for i in df.Body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Document sizes for the complete data set, size is a word in this case\n",
    "plt.hist(document_sizes)\n",
    "plt.title('document sizes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quality counts for question is exactly the same\n",
    "df.Y.value_counts().plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Java: Repeat Task Every Random Seconds I'm alr...\n",
       "1        How to get all the child records from differen...\n",
       "2        Why are Java Optionals immutable? I'd like to ...\n",
       "3        Text Overlay Image with Darkened Opacity React...\n",
       "4        Why ternary operator in swift is so picky? The...\n",
       "                               ...                        \n",
       "59995    C++ The correct way to multiply an integer and...\n",
       "59996    How can I make a c# application outside of vis...\n",
       "59997    WHY DJANGO IS SHOWING ME THIS ERROR WHEN I TRY...\n",
       "59998    PHP - getting the content of php page I have a...\n",
       "59999    Why can't overloaded functions vary only by re...\n",
       "Name: text, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to only keep alphabet characters inside the text\n",
    "def data_cleaning(data):\n",
    "    data = data.lower()\n",
    "    data = re.sub(r'[^(a-zA-Z)\\s]','',data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_X = pd.DataFrame({'text':clean_X}).text.apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        java repeat task every random seconds im alrea...\n",
       "1        how to get all the child records from differen...\n",
       "2        why are java optionals immutable id like to un...\n",
       "3        text overlay image with darkened opacity react...\n",
       "4        why ternary operator in swift is so picky the ...\n",
       "                               ...                        \n",
       "59995    c the correct way to multiply an integer and a...\n",
       "59996    how can i make a c application outside of visu...\n",
       "59997    why django is showing me this error when i try...\n",
       "59998    php  getting the content of php page i have a ...\n",
       "59999    why cant overloaded functions vary only by ret...\n",
       "Name: text, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 10000\n",
    "MAX_LEN = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=MAX_NUM_WORDS, output_sequence_length=MAX_LEN)\n",
    "#text_ds = tf.data.Dataset.from_tensor_slices(clean_X).batch(128)\n",
    "#vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voc = [i.decode('utf-8') for i in vectorizer.get_vocabulary()]\n",
    "#word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "\n",
    "#tokenizer.fit_on_texts(clean_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "#x_test = vectorizer(np.array([[s] for s in X_test])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode labels\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df.Y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_X, y, train_size = 0.80, random_state = 42, shuffle = True, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(tokenized_train, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(tokenized_test, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_glove_file = 'glove.twitter.27B.200d.txt'\n",
    "\n",
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding = 'utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(MAX_NUM_WORDS, len(word_index))\n",
    "#change below line if computing normal stats is too slow\n",
    "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model for quality prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dropout, Embedding, SpatialDropout1D, Dense, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final experiments with Bidirectional LSTMs to improve performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, output_dim=200, weights=[embedding_matrix], input_length=MAX_LEN, trainable=True))\n",
    "model.add(Bidirectional(LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.4 , dropout = 0.4)))\n",
    "model.add(Bidirectional(LSTM(units=128 , recurrent_dropout = 0.2 , dropout = 0.2)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 300, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 300, 256)          336896    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,731,907\n",
      "Trainable params: 2,731,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First experiment tries to use bidirectional LSTM along with Glove embeddings for the glove.twitter.27B.200.txt file. It sets the embeddings as trainable parameters to fine tune the weights and improve accuracy at prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.4, min_lr=0.0000001), ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpcar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 157s 3ms/step - loss: 0.6091 - accuracy: 0.7106 - val_loss: 0.4859 - val_accuracy: 0.8017\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 155s 3ms/step - loss: 0.4523 - accuracy: 0.8233 - val_loss: 0.4072 - val_accuracy: 0.8485\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 155s 3ms/step - loss: 0.3907 - accuracy: 0.8552 - val_loss: 0.3665 - val_accuracy: 0.8643\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 155s 3ms/step - loss: 0.3515 - accuracy: 0.8702 - val_loss: 0.3384 - val_accuracy: 0.8717\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 155s 3ms/step - loss: 0.3238 - accuracy: 0.8808 - val_loss: 0.3359 - val_accuracy: 0.8739\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 256 , validation_data = (X_test,y_test) , epochs = 5 , callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, output_dim=200, weights=[embedding_matrix], input_length=MAX_LEN, trainable=False))\n",
    "model.add(Bidirectional(LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.4 , dropout = 0.4)))\n",
    "model.add(Bidirectional(LSTM(units=128 , recurrent_dropout = 0.2 , dropout = 0.2)))\n",
    "model.add(Dense(64))\n",
    "model.add(keras.layers.LeakyReLU())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 300, 200)          2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 300, 256)          336896    \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 2,747,779\n",
      "Trainable params: 747,779\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model decided, this is used to reduce the total number of trainable parameters. Due to time contraints, training is done for only 20 epochs. But this model may have yielded better results if trained for more epochs. Use a Leaky RELU activation in the first dense layer as experimentation. No dropout used between dense layers. Dropout used in both bidirectional LSTM cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 149s 3ms/step - loss: 0.6292 - accuracy: 0.6957 - val_loss: 0.5294 - val_accuracy: 0.7598\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.5432 - accuracy: 0.7633 - val_loss: 0.4799 - val_accuracy: 0.8022\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 0.5054 - accuracy: 0.7870 - val_loss: 0.4512 - val_accuracy: 0.8139\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.4753 - accuracy: 0.8007 - val_loss: 0.4324 - val_accuracy: 0.8276\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.4495 - accuracy: 0.8156 - val_loss: 0.4110 - val_accuracy: 0.8371\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.4298 - accuracy: 0.8257 - val_loss: 0.3785 - val_accuracy: 0.8499\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 0.4080 - accuracy: 0.8365 - val_loss: 0.3631 - val_accuracy: 0.8587\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.3947 - accuracy: 0.8431 - val_loss: 0.3792 - val_accuracy: 0.8514\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 0.3823 - accuracy: 0.8472 - val_loss: 0.3515 - val_accuracy: 0.8631\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 0.3691 - accuracy: 0.8547 - val_loss: 0.3473 - val_accuracy: 0.8634\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.3620 - accuracy: 0.8578 - val_loss: 0.3346 - val_accuracy: 0.8679\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 0.3538 - accuracy: 0.8599 - val_loss: 0.3398 - val_accuracy: 0.8633\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 144s 3ms/step - loss: 0.3434 - accuracy: 0.8645 - val_loss: 0.3258 - val_accuracy: 0.8706\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.3366 - accuracy: 0.8677 - val_loss: 0.3245 - val_accuracy: 0.8710\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.3284 - accuracy: 0.8716 - val_loss: 0.3263 - val_accuracy: 0.8738\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.3248 - accuracy: 0.8705 - val_loss: 0.3179 - val_accuracy: 0.8714\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.3186 - accuracy: 0.8746 - val_loss: 0.3237 - val_accuracy: 0.8731\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 144s 3ms/step - loss: 0.3041 - accuracy: 0.8795 - val_loss: 0.3173 - val_accuracy: 0.8753\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.3004 - accuracy: 0.8812 - val_loss: 0.3176 - val_accuracy: 0.8751\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 146s 3ms/step - loss: 0.2978 - accuracy: 0.8826 - val_loss: 0.3148 - val_accuracy: 0.8758\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 256 , validation_data = (X_test,y_test) , epochs = 20 , callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, training could have been kept going but for time constraint reasons it was stopped early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the experiments that were attempted to create the best LSTM model. Long story short. None of them worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, 150, input_length = (256)))\n",
    "model.add(LSTM(64, dropout=0.5, recurrent_dropout= 0.2))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 256, 150)          2250000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                55040     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 2,307,219\n",
      "Trainable params: 2,307,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model consists of an LSTM cell with 64 passes, along with two feed forward layers that compute the softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', min_delta=0,  patience=10, verbose=0, mode='auto'),ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43350 samples, validate on 7650 samples\n",
      "Epoch 1/50\n",
      "43350/43350 [==============================] - 71s 2ms/step - loss: 0.6654 - accuracy: 0.7177 - val_loss: 0.7740 - val_accuracy: 0.6638\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpcar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43350/43350 [==============================] - 70s 2ms/step - loss: 0.6092 - accuracy: 0.7442 - val_loss: 0.8049 - val_accuracy: 0.6624\n",
      "Epoch 3/50\n",
      "43350/43350 [==============================] - 70s 2ms/step - loss: 0.5694 - accuracy: 0.7637 - val_loss: 0.8406 - val_accuracy: 0.6527\n",
      "Epoch 4/50\n",
      "27136/43350 [=================>............] - ETA: 25s - loss: 0.5394 - accuracy: 0.7806"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-4c8d01c5da69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size= 128, epochs=50, validation_split=0.15 ,callbacks = callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training interrupted due to poor results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, 64, input_length = (192)))\n",
    "model.add(LSTM(128, dropout=0.5, recurrent_dropout= 0.5, return_sequences= True))\n",
    "model.add(LSTM(128, dropout=0.5, recurrent_dropout= 0.5))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 192, 64)           960000    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 192, 128)          98816     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,190,787\n",
      "Trainable params: 1,190,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second attempt at creating a vanilla LSTM network, with two LSTM layers, the first one which returns a sequence and the second one which returns the actual weights to compute the softmax. In this experiment the embedding is being learned from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',optimizer= 'rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpcar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43350 samples, validate on 7650 samples\n",
      "Epoch 1/50\n",
      "43350/43350 [==============================] - 27s 618us/step - loss: 0.9575 - accuracy: 0.5187 - val_loss: 0.9067 - val_accuracy: 0.5629\n",
      "Epoch 2/50\n",
      "43350/43350 [==============================] - 26s 610us/step - loss: 0.9551 - accuracy: 0.5197 - val_loss: 0.9161 - val_accuracy: 0.5476\n",
      "Epoch 3/50\n",
      "43350/43350 [==============================] - 27s 617us/step - loss: 0.9544 - accuracy: 0.5251 - val_loss: 0.9041 - val_accuracy: 0.5593\n",
      "Epoch 4/50\n",
      "43350/43350 [==============================] - 26s 608us/step - loss: 0.9542 - accuracy: 0.5210 - val_loss: 0.8965 - val_accuracy: 0.5735\n",
      "Epoch 5/50\n",
      "43350/43350 [==============================] - 26s 607us/step - loss: 0.9532 - accuracy: 0.5213 - val_loss: 0.8978 - val_accuracy: 0.5676\n",
      "Epoch 6/50\n",
      "43350/43350 [==============================] - 26s 609us/step - loss: 0.9532 - accuracy: 0.5207 - val_loss: 0.8926 - val_accuracy: 0.5708\n",
      "Epoch 7/50\n",
      "43350/43350 [==============================] - 27s 613us/step - loss: 0.9501 - accuracy: 0.5250 - val_loss: 0.8867 - val_accuracy: 0.5718\n",
      "Epoch 8/50\n",
      "43350/43350 [==============================] - 26s 606us/step - loss: 0.9488 - accuracy: 0.5266 - val_loss: 0.8870 - val_accuracy: 0.5753\n",
      "Epoch 9/50\n",
      "43350/43350 [==============================] - 26s 608us/step - loss: 0.9516 - accuracy: 0.5249 - val_loss: 0.8907 - val_accuracy: 0.5748\n",
      "Epoch 10/50\n",
      "43350/43350 [==============================] - 27s 614us/step - loss: 0.9493 - accuracy: 0.5274 - val_loss: 0.8820 - val_accuracy: 0.5799\n",
      "Epoch 11/50\n",
      "43350/43350 [==============================] - 26s 610us/step - loss: 0.9429 - accuracy: 0.5282 - val_loss: 0.8867 - val_accuracy: 0.5782\n",
      "Epoch 12/50\n",
      "43350/43350 [==============================] - 26s 610us/step - loss: 0.9451 - accuracy: 0.5292 - val_loss: 0.8763 - val_accuracy: 0.5846\n",
      "Epoch 13/50\n",
      "43350/43350 [==============================] - 27s 616us/step - loss: 0.9449 - accuracy: 0.5268 - val_loss: 0.8819 - val_accuracy: 0.5767\n",
      "Epoch 14/50\n",
      "43350/43350 [==============================] - 26s 604us/step - loss: 0.9426 - accuracy: 0.5300 - val_loss: 0.8746 - val_accuracy: 0.5835\n",
      "Epoch 15/50\n",
      "43350/43350 [==============================] - 26s 603us/step - loss: 0.9446 - accuracy: 0.5297 - val_loss: 0.8770 - val_accuracy: 0.5844\n",
      "Epoch 16/50\n",
      "43350/43350 [==============================] - 26s 602us/step - loss: 0.9431 - accuracy: 0.5283 - val_loss: 0.8802 - val_accuracy: 0.5790\n",
      "Epoch 17/50\n",
      "43350/43350 [==============================] - 26s 604us/step - loss: 0.9437 - accuracy: 0.5303 - val_loss: 0.8785 - val_accuracy: 0.5817\n",
      "Epoch 18/50\n",
      "43350/43350 [==============================] - 26s 603us/step - loss: 0.9400 - accuracy: 0.5330 - val_loss: 0.8754 - val_accuracy: 0.5826\n",
      "Epoch 19/50\n",
      "43350/43350 [==============================] - 26s 605us/step - loss: 0.9434 - accuracy: 0.5272 - val_loss: 0.8759 - val_accuracy: 0.5803\n",
      "Epoch 20/50\n",
      "43350/43350 [==============================] - 26s 603us/step - loss: 0.9404 - accuracy: 0.5309 - val_loss: 0.8727 - val_accuracy: 0.5824\n",
      "Epoch 21/50\n",
      "43350/43350 [==============================] - 26s 603us/step - loss: 0.9420 - accuracy: 0.5268 - val_loss: 0.8770 - val_accuracy: 0.5800\n",
      "Epoch 22/50\n",
      "43350/43350 [==============================] - 26s 602us/step - loss: 0.9389 - accuracy: 0.5310 - val_loss: 0.8731 - val_accuracy: 0.5818\n",
      "Epoch 23/50\n",
      "43350/43350 [==============================] - 26s 607us/step - loss: 0.9335 - accuracy: 0.5375 - val_loss: 0.8709 - val_accuracy: 0.5841\n",
      "Epoch 24/50\n",
      "43350/43350 [==============================] - 26s 608us/step - loss: 0.9417 - accuracy: 0.5296 - val_loss: 0.8735 - val_accuracy: 0.5812\n",
      "Epoch 25/50\n",
      "43350/43350 [==============================] - 26s 607us/step - loss: 0.9356 - accuracy: 0.5354 - val_loss: 0.8684 - val_accuracy: 0.5818\n",
      "Epoch 26/50\n",
      "43350/43350 [==============================] - 26s 609us/step - loss: 0.9350 - accuracy: 0.5365 - val_loss: 0.8710 - val_accuracy: 0.5825\n",
      "Epoch 27/50\n",
      "43350/43350 [==============================] - 26s 607us/step - loss: 0.9334 - accuracy: 0.5356 - val_loss: 0.8662 - val_accuracy: 0.5897\n",
      "Epoch 28/50\n",
      "43350/43350 [==============================] - 26s 606us/step - loss: 0.9370 - accuracy: 0.5306 - val_loss: 0.8616 - val_accuracy: 0.5837\n",
      "Epoch 29/50\n",
      "43350/43350 [==============================] - 26s 606us/step - loss: 0.9333 - accuracy: 0.5343 - val_loss: 0.8609 - val_accuracy: 0.5858\n",
      "Epoch 30/50\n",
      "43350/43350 [==============================] - 26s 605us/step - loss: 0.9384 - accuracy: 0.5332 - val_loss: 0.8733 - val_accuracy: 0.5816\n",
      "Epoch 31/50\n",
      "43350/43350 [==============================] - 26s 608us/step - loss: 0.9329 - accuracy: 0.5366 - val_loss: 0.8720 - val_accuracy: 0.5816\n",
      "Epoch 32/50\n",
      "43350/43350 [==============================] - 26s 605us/step - loss: 0.9316 - accuracy: 0.5375 - val_loss: 0.8656 - val_accuracy: 0.5854\n",
      "Epoch 33/50\n",
      "43350/43350 [==============================] - 26s 607us/step - loss: 0.9382 - accuracy: 0.5293 - val_loss: 0.8654 - val_accuracy: 0.5848\n",
      "Epoch 34/50\n",
      "43350/43350 [==============================] - 26s 605us/step - loss: 0.9343 - accuracy: 0.5330 - val_loss: 0.8592 - val_accuracy: 0.5884\n",
      "Epoch 35/50\n",
      "43350/43350 [==============================] - 26s 607us/step - loss: 0.9323 - accuracy: 0.5334 - val_loss: 0.8628 - val_accuracy: 0.5905\n",
      "Epoch 36/50\n",
      "43350/43350 [==============================] - 26s 610us/step - loss: 0.9363 - accuracy: 0.5328 - val_loss: 0.8600 - val_accuracy: 0.5831\n",
      "Epoch 37/50\n",
      "43350/43350 [==============================] - 26s 610us/step - loss: 0.9315 - accuracy: 0.5336 - val_loss: 0.8576 - val_accuracy: 0.5873\n",
      "Epoch 38/50\n",
      "43350/43350 [==============================] - 26s 611us/step - loss: 0.9289 - accuracy: 0.5386 - val_loss: 0.8586 - val_accuracy: 0.5854\n",
      "Epoch 39/50\n",
      "43350/43350 [==============================] - 26s 611us/step - loss: 0.9341 - accuracy: 0.5391 - val_loss: 0.8565 - val_accuracy: 0.5867\n",
      "Epoch 40/50\n",
      "43350/43350 [==============================] - 26s 610us/step - loss: 0.9275 - accuracy: 0.5418 - val_loss: 0.8587 - val_accuracy: 0.5839\n",
      "Epoch 41/50\n",
      "43350/43350 [==============================] - 26s 607us/step - loss: 0.9292 - accuracy: 0.5390 - val_loss: 0.8616 - val_accuracy: 0.5860\n",
      "Epoch 42/50\n",
      "43350/43350 [==============================] - 26s 608us/step - loss: 0.9306 - accuracy: 0.5367 - val_loss: 0.8621 - val_accuracy: 0.5803\n",
      "Epoch 43/50\n",
      "43350/43350 [==============================] - 26s 610us/step - loss: 0.9273 - accuracy: 0.5407 - val_loss: 0.8669 - val_accuracy: 0.5739\n",
      "Epoch 44/50\n",
      "32256/43350 [=====================>........] - ETA: 6s - loss: 0.9305 - accuracy: 0.5384"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-d64d6a01dbb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size= 512, epochs=50, validation_split=0.15 ,callbacks = callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop=tf.keras.optimizers.RMSprop(learning_rate=0.005)\n",
    "model.compile(loss='categorical_crossentropy',optimizer= rmsprop ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43350 samples, validate on 7650 samples\n",
      "Epoch 1/50\n",
      "43350/43350 [==============================] - 27s 622us/step - loss: 0.9332 - accuracy: 0.5375 - val_loss: 0.8544 - val_accuracy: 0.5878\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpcar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43350/43350 [==============================] - 26s 606us/step - loss: 0.9331 - accuracy: 0.5369 - val_loss: 0.8609 - val_accuracy: 0.5826\n",
      "Epoch 3/50\n",
      "43350/43350 [==============================] - 26s 604us/step - loss: 0.9319 - accuracy: 0.5364 - val_loss: 0.8603 - val_accuracy: 0.5851\n",
      "Epoch 4/50\n",
      "43350/43350 [==============================] - 26s 609us/step - loss: 0.9277 - accuracy: 0.5379 - val_loss: 0.8696 - val_accuracy: 0.5711\n",
      "Epoch 5/50\n",
      "43350/43350 [==============================] - 27s 614us/step - loss: 0.9306 - accuracy: 0.5381 - val_loss: 0.8601 - val_accuracy: 0.5809\n",
      "Epoch 6/50\n",
      "43350/43350 [==============================] - 26s 608us/step - loss: 0.9284 - accuracy: 0.5401 - val_loss: 0.8715 - val_accuracy: 0.5750\n",
      "Epoch 7/50\n",
      "43350/43350 [==============================] - 26s 607us/step - loss: 0.9283 - accuracy: 0.5406 - val_loss: 0.8566 - val_accuracy: 0.5906\n",
      "Epoch 8/50\n",
      "43350/43350 [==============================] - 26s 605us/step - loss: 0.9261 - accuracy: 0.5419 - val_loss: 0.8611 - val_accuracy: 0.5855\n",
      "Epoch 9/50\n",
      "43350/43350 [==============================] - 26s 607us/step - loss: 0.9257 - accuracy: 0.5410 - val_loss: 0.8614 - val_accuracy: 0.5861\n",
      "Epoch 10/50\n",
      "43350/43350 [==============================] - 28s 640us/step - loss: 0.9250 - accuracy: 0.5413 - val_loss: 0.8489 - val_accuracy: 0.5986\n",
      "Epoch 11/50\n",
      "43350/43350 [==============================] - 26s 609us/step - loss: 0.9197 - accuracy: 0.5444 - val_loss: 0.8567 - val_accuracy: 0.5808\n",
      "Epoch 12/50\n",
      "43350/43350 [==============================] - 26s 606us/step - loss: 0.9205 - accuracy: 0.5442 - val_loss: 0.8458 - val_accuracy: 0.5999\n",
      "Epoch 13/50\n",
      "43350/43350 [==============================] - 26s 608us/step - loss: 0.9189 - accuracy: 0.5426 - val_loss: 0.8537 - val_accuracy: 0.5872\n",
      "Epoch 14/50\n",
      "33280/43350 [======================>.......] - ETA: 5s - loss: 0.9159 - accuracy: 0.5467"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-d64d6a01dbb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size= 512, epochs=50, validation_split=0.15 ,callbacks = callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, 64, input_length = (192)))\n",
    "model.add(LSTM(64, dropout=0.25, recurrent_dropout= 0.25))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to poor results, and failure to generalize on the validation set a new model is created with less capacity, to see if overfitting is the main problem in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer= rmsprop ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43350 samples, validate on 7650 samples\n",
      "Epoch 1/50\n",
      "43350/43350 [==============================] - 11s 262us/step - loss: 0.9087 - accuracy: 0.5530 - val_loss: 0.8410 - val_accuracy: 0.6080\n",
      "Epoch 2/50\n",
      "  512/43350 [..............................] - ETA: 11s - loss: 0.8268 - accuracy: 0.6211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpcar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43350/43350 [==============================] - 11s 257us/step - loss: 0.7746 - accuracy: 0.6445 - val_loss: 0.7597 - val_accuracy: 0.6549\n",
      "Epoch 3/50\n",
      "43350/43350 [==============================] - 11s 252us/step - loss: 0.7119 - accuracy: 0.6831 - val_loss: 0.7754 - val_accuracy: 0.6506\n",
      "Epoch 4/50\n",
      "43350/43350 [==============================] - 11s 252us/step - loss: 0.6608 - accuracy: 0.7112 - val_loss: 0.8247 - val_accuracy: 0.6383\n",
      "Epoch 5/50\n",
      "43350/43350 [==============================] - 11s 253us/step - loss: 0.6169 - accuracy: 0.7372 - val_loss: 0.7857 - val_accuracy: 0.6593\n",
      "Epoch 6/50\n",
      "43350/43350 [==============================] - 11s 252us/step - loss: 0.5794 - accuracy: 0.7542 - val_loss: 0.8168 - val_accuracy: 0.6468\n",
      "Epoch 7/50\n",
      "43350/43350 [==============================] - 11s 254us/step - loss: 0.5385 - accuracy: 0.7761 - val_loss: 0.7838 - val_accuracy: 0.6458\n",
      "Epoch 8/50\n",
      "43350/43350 [==============================] - 11s 252us/step - loss: 0.5037 - accuracy: 0.7938 - val_loss: 0.8313 - val_accuracy: 0.6482\n",
      "Epoch 9/50\n",
      "43350/43350 [==============================] - 11s 254us/step - loss: 0.4678 - accuracy: 0.8112 - val_loss: 0.8704 - val_accuracy: 0.6477\n",
      "Epoch 10/50\n",
      "43350/43350 [==============================] - 11s 255us/step - loss: 0.4278 - accuracy: 0.8290 - val_loss: 0.9023 - val_accuracy: 0.6497\n",
      "Epoch 11/50\n",
      "43350/43350 [==============================] - 11s 254us/step - loss: 0.3983 - accuracy: 0.8431 - val_loss: 0.9435 - val_accuracy: 0.6518\n",
      "Epoch 12/50\n",
      "43350/43350 [==============================] - 11s 254us/step - loss: 0.3689 - accuracy: 0.8563 - val_loss: 0.9940 - val_accuracy: 0.6431\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size= 512, epochs=50, validation_split=0.15 ,callbacks = callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, 64, input_length = (192)))\n",
    "model.add(LSTM(64, dropout=0.25, recurrent_dropout= 0.25, recurrent_regularizer= \"l2\"))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer= rmsprop ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43350 samples, validate on 7650 samples\n",
      "Epoch 1/50\n",
      "43350/43350 [==============================] - 11s 259us/step - loss: 0.9599 - accuracy: 0.5547 - val_loss: 0.8345 - val_accuracy: 0.6190\n",
      "Epoch 2/50\n",
      "  512/43350 [..............................] - ETA: 10s - loss: 0.8472 - accuracy: 0.6172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpcar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43350/43350 [==============================] - 11s 251us/step - loss: 0.7890 - accuracy: 0.6448 - val_loss: 0.8540 - val_accuracy: 0.6125\n",
      "Epoch 3/50\n",
      "43350/43350 [==============================] - 11s 253us/step - loss: 0.7400 - accuracy: 0.6807 - val_loss: 0.8233 - val_accuracy: 0.6373\n",
      "Epoch 4/50\n",
      "43350/43350 [==============================] - 11s 250us/step - loss: 0.7038 - accuracy: 0.6962 - val_loss: 0.8110 - val_accuracy: 0.6322\n",
      "Epoch 5/50\n",
      "43350/43350 [==============================] - 11s 251us/step - loss: 0.6567 - accuracy: 0.7208 - val_loss: 0.8046 - val_accuracy: 0.6429\n",
      "Epoch 6/50\n",
      "43350/43350 [==============================] - 11s 250us/step - loss: 0.6201 - accuracy: 0.7382 - val_loss: 0.8246 - val_accuracy: 0.6431\n",
      "Epoch 7/50\n",
      "43350/43350 [==============================] - 11s 250us/step - loss: 0.5806 - accuracy: 0.7542 - val_loss: 0.8403 - val_accuracy: 0.6489\n",
      "Epoch 8/50\n",
      "43350/43350 [==============================] - 11s 251us/step - loss: 0.5389 - accuracy: 0.7759 - val_loss: 0.8656 - val_accuracy: 0.6476\n",
      "Epoch 9/50\n",
      "43350/43350 [==============================] - 11s 251us/step - loss: 0.5024 - accuracy: 0.7958 - val_loss: 0.8594 - val_accuracy: 0.6421\n",
      "Epoch 10/50\n",
      "43350/43350 [==============================] - 11s 251us/step - loss: 0.4669 - accuracy: 0.8103 - val_loss: 0.9014 - val_accuracy: 0.6380\n",
      "Epoch 11/50\n",
      "43350/43350 [==============================] - 11s 252us/step - loss: 0.4297 - accuracy: 0.8300 - val_loss: 0.9458 - val_accuracy: 0.6424\n",
      "Epoch 12/50\n",
      "43350/43350 [==============================] - 11s 250us/step - loss: 0.4013 - accuracy: 0.8407 - val_loss: 0.9779 - val_accuracy: 0.6370\n",
      "Epoch 13/50\n",
      "43350/43350 [==============================] - 11s 251us/step - loss: 0.3726 - accuracy: 0.8537 - val_loss: 1.0355 - val_accuracy: 0.6278\n",
      "Epoch 14/50\n",
      "43350/43350 [==============================] - 11s 253us/step - loss: 0.3479 - accuracy: 0.8649 - val_loss: 1.0496 - val_accuracy: 0.6358\n",
      "Epoch 15/50\n",
      "43350/43350 [==============================] - 11s 251us/step - loss: 0.3254 - accuracy: 0.8751 - val_loss: 1.1162 - val_accuracy: 0.6382\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size= 512, epochs=50, validation_split=0.15 ,callbacks = callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NUM_WORDS, 32, input_length = (100)))\n",
    "model.add(LSTM(32, dropout=0.25, recurrent_dropout= 0.25, recurrent_regularizer= \"l2\"))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_42 (Embedding)     (None, 100, 32)           640000    \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 648,419\n",
      "Trainable params: 648,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next attempt to create a vanilla LSTM with very small capacity, due to the training problems. Overfitting does not seem ot be the issue because training accuracy is not improving that much as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer= rmsprop ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43350 samples, validate on 7650 samples\n",
      "Epoch 1/50\n",
      "43350/43350 [==============================] - 6s 136us/step - loss: 0.9206 - accuracy: 0.5621 - val_loss: 0.8619 - val_accuracy: 0.5971\n",
      "Epoch 2/50\n",
      " 1024/43350 [..............................] - ETA: 5s - loss: 0.8213 - accuracy: 0.62"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpcar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43350/43350 [==============================] - 6s 129us/step - loss: 0.7720 - accuracy: 0.6447 - val_loss: 0.8035 - val_accuracy: 0.6275\n",
      "Epoch 3/50\n",
      "43350/43350 [==============================] - 6s 128us/step - loss: 0.7194 - accuracy: 0.6799 - val_loss: 0.8080 - val_accuracy: 0.6227\n",
      "Epoch 4/50\n",
      "43350/43350 [==============================] - 6s 129us/step - loss: 0.6814 - accuracy: 0.6982 - val_loss: 0.8238 - val_accuracy: 0.6166\n",
      "Epoch 5/50\n",
      "43350/43350 [==============================] - 6s 128us/step - loss: 0.6525 - accuracy: 0.7162 - val_loss: 0.8161 - val_accuracy: 0.6261\n",
      "Epoch 6/50\n",
      "43350/43350 [==============================] - 6s 129us/step - loss: 0.6304 - accuracy: 0.7284 - val_loss: 0.8314 - val_accuracy: 0.6295\n",
      "Epoch 7/50\n",
      "18944/43350 [============>.................] - ETA: 3s - loss: 0.5884 - accuracy: 0.7488"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-312-d64d6a01dbb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size= 512, epochs=50, validation_split=0.15 ,callbacks = callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Embedding(MAX_NUM_WORDS, 24, input_length = (100)))\n",
    "model_1.add(LSTM(16, dropout=0.5, recurrent_dropout= 0.25, recurrent_regularizer= \"l1_l2\", bias_regularizer= \"l2\"))\n",
    "model_1.add(Dense(16, activation = 'relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_44 (Embedding)     (None, 100, 24)           60000     \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 16)                2624      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 63,011\n",
      "Trainable params: 62,979\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss='categorical_crossentropy',optimizer= rmsprop ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51000 samples, validate on 9000 samples\n",
      "Epoch 1/50\n",
      "51000/51000 [==============================] - 7s 140us/step - loss: 1.1935 - accuracy: 0.5346 - val_loss: 1.1498 - val_accuracy: 0.3723\n",
      "Epoch 2/50\n",
      " 1024/51000 [..............................] - ETA: 6s - loss: 0.9196 - accuracy: 0.6201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpcar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.9184 - accuracy: 0.5961 - val_loss: 1.0628 - val_accuracy: 0.5182\n",
      "Epoch 3/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.8826 - accuracy: 0.6099 - val_loss: 0.9985 - val_accuracy: 0.5392\n",
      "Epoch 4/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.8694 - accuracy: 0.6187 - val_loss: 0.9249 - val_accuracy: 0.5798\n",
      "Epoch 5/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.8600 - accuracy: 0.6220 - val_loss: 0.9056 - val_accuracy: 0.5877\n",
      "Epoch 6/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.8521 - accuracy: 0.6258 - val_loss: 0.9071 - val_accuracy: 0.5867\n",
      "Epoch 7/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.8447 - accuracy: 0.6301 - val_loss: 0.9070 - val_accuracy: 0.5937\n",
      "Epoch 8/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.8406 - accuracy: 0.6342 - val_loss: 0.8905 - val_accuracy: 0.5957\n",
      "Epoch 9/50\n",
      "51000/51000 [==============================] - 7s 135us/step - loss: 0.8345 - accuracy: 0.6372 - val_loss: 0.9065 - val_accuracy: 0.5948\n",
      "Epoch 10/50\n",
      "51000/51000 [==============================] - 7s 134us/step - loss: 0.8319 - accuracy: 0.6371 - val_loss: 0.8865 - val_accuracy: 0.6043\n",
      "Epoch 11/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.8241 - accuracy: 0.6379 - val_loss: 0.8735 - val_accuracy: 0.6052\n",
      "Epoch 12/50\n",
      "51000/51000 [==============================] - 7s 133us/step - loss: 0.8151 - accuracy: 0.6445 - val_loss: 0.8784 - val_accuracy: 0.6110\n",
      "Epoch 13/50\n",
      "51000/51000 [==============================] - 7s 133us/step - loss: 0.8075 - accuracy: 0.6437 - val_loss: 0.8694 - val_accuracy: 0.6089\n",
      "Epoch 14/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.8001 - accuracy: 0.6497 - val_loss: 0.9173 - val_accuracy: 0.5939\n",
      "Epoch 15/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.7929 - accuracy: 0.6514 - val_loss: 0.8535 - val_accuracy: 0.6183\n",
      "Epoch 16/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.7855 - accuracy: 0.6544 - val_loss: 0.8716 - val_accuracy: 0.6118\n",
      "Epoch 17/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.7819 - accuracy: 0.6566 - val_loss: 0.8379 - val_accuracy: 0.6259\n",
      "Epoch 18/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.7736 - accuracy: 0.6611 - val_loss: 0.8814 - val_accuracy: 0.6181\n",
      "Epoch 19/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.7727 - accuracy: 0.6611 - val_loss: 0.8326 - val_accuracy: 0.6264\n",
      "Epoch 20/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.7651 - accuracy: 0.6639 - val_loss: 0.8380 - val_accuracy: 0.6299\n",
      "Epoch 21/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.7608 - accuracy: 0.6649 - val_loss: 0.8406 - val_accuracy: 0.6313\n",
      "Epoch 22/50\n",
      "51000/51000 [==============================] - 7s 133us/step - loss: 0.7589 - accuracy: 0.6696 - val_loss: 0.8252 - val_accuracy: 0.6268\n",
      "Epoch 23/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.7542 - accuracy: 0.6709 - val_loss: 0.8342 - val_accuracy: 0.6236\n",
      "Epoch 24/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.7517 - accuracy: 0.6719 - val_loss: 0.8228 - val_accuracy: 0.6322\n",
      "Epoch 25/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.7485 - accuracy: 0.6716 - val_loss: 0.8465 - val_accuracy: 0.6239\n",
      "Epoch 26/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.7480 - accuracy: 0.6735 - val_loss: 0.8273 - val_accuracy: 0.6322\n",
      "Epoch 27/50\n",
      "51000/51000 [==============================] - 7s 131us/step - loss: 0.7447 - accuracy: 0.6747 - val_loss: 0.8330 - val_accuracy: 0.6217\n",
      "Epoch 28/50\n",
      "51000/51000 [==============================] - 7s 135us/step - loss: 0.7413 - accuracy: 0.6788 - val_loss: 0.8159 - val_accuracy: 0.6364\n",
      "Epoch 29/50\n",
      "51000/51000 [==============================] - 7s 133us/step - loss: 0.7414 - accuracy: 0.6761 - val_loss: 0.8204 - val_accuracy: 0.6273\n",
      "Epoch 30/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.7389 - accuracy: 0.6780 - val_loss: 0.8282 - val_accuracy: 0.6381\n",
      "Epoch 31/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.7363 - accuracy: 0.6800 - val_loss: 0.8285 - val_accuracy: 0.6356\n",
      "Epoch 32/50\n",
      "51000/51000 [==============================] - 7s 133us/step - loss: 0.7353 - accuracy: 0.6801 - val_loss: 0.8196 - val_accuracy: 0.6314\n",
      "Epoch 33/50\n",
      "51000/51000 [==============================] - 7s 132us/step - loss: 0.7333 - accuracy: 0.6812 - val_loss: 0.8209 - val_accuracy: 0.6357\n",
      "Epoch 34/50\n",
      "34304/51000 [===================>..........] - ETA: 2s - loss: 0.7306 - accuracy: 0.6838"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-339-5cc10c101c30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model_1.fit(X_train, y_train, batch_size= 512, epochs=50, validation_data=(X_test, y_test) ,callbacks = callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 1,\n",
       " 'new': 2,\n",
       " 'string': 3,\n",
       " 'int': 4,\n",
       " 'using': 5,\n",
       " 'error': 6,\n",
       " 'like': 7,\n",
       " 'file': 8,\n",
       " 'want': 9,\n",
       " 'return': 10,\n",
       " 'public': 11,\n",
       " 'get': 12,\n",
       " 'im': 13,\n",
       " 'function': 14,\n",
       " 'use': 15,\n",
       " 'class': 16,\n",
       " 'data': 17,\n",
       " 'c': 18,\n",
       " 'value': 19,\n",
       " 'import': 20,\n",
       " 'name': 21,\n",
       " 'void': 22,\n",
       " 'x': 23,\n",
       " 'would': 24,\n",
       " 'array': 25,\n",
       " 'help': 26,\n",
       " 'one': 27,\n",
       " 'need': 28,\n",
       " 'var': 29,\n",
       " 'way': 30,\n",
       " 'list': 31,\n",
       " 'trying': 32,\n",
       " 'id': 33,\n",
       " 'print': 34,\n",
       " 'line': 35,\n",
       " 'number': 36,\n",
       " 'else': 37,\n",
       " 'know': 38,\n",
       " 'user': 39,\n",
       " 'app': 40,\n",
       " 'please': 41,\n",
       " 'null': 42,\n",
       " 'input': 43,\n",
       " 'type': 44,\n",
       " 'b': 45,\n",
       " 'set': 46,\n",
       " 'following': 47,\n",
       " 'object': 48,\n",
       " 'text': 49,\n",
       " 'true': 50,\n",
       " 'create': 51,\n",
       " 'make': 52,\n",
       " 'work': 53,\n",
       " 'time': 54,\n",
       " 'find': 55,\n",
       " 'run': 56,\n",
       " 'tried': 57,\n",
       " 'python': 58,\n",
       " 'method': 59,\n",
       " 'example': 60,\n",
       " 'n': 61,\n",
       " 'dont': 62,\n",
       " 'problem': 63,\n",
       " 'div': 64,\n",
       " 'private': 65,\n",
       " 'thanks': 66,\n",
       " 'i': 67,\n",
       " 'table': 68,\n",
       " 'first': 69,\n",
       " 'main': 70,\n",
       " 'image': 71,\n",
       " 'add': 72,\n",
       " 'output': 73,\n",
       " 'button': 74,\n",
       " 'test': 75,\n",
       " 'two': 76,\n",
       " 'result': 77,\n",
       " 'false': 78,\n",
       " 'values': 79,\n",
       " 'if': 80,\n",
       " 'working': 81,\n",
       " 'android': 82,\n",
       " 'ive': 83,\n",
       " 'e': 84,\n",
       " 'also': 85,\n",
       " 'view': 86,\n",
       " 'project': 87,\n",
       " 'try': 88,\n",
       " 'static': 89,\n",
       " 'cant': 90,\n",
       " 'something': 91,\n",
       " 'could': 92,\n",
       " 'php': 93,\n",
       " 'date': 94,\n",
       " 'case': 95,\n",
       " 'java': 96,\n",
       " 'end': 97,\n",
       " 'select': 98,\n",
       " 'application': 99,\n",
       " 'server': 100,\n",
       " 'page': 101,\n",
       " 'html': 102,\n",
       " 'enter': 103,\n",
       " 'version': 104,\n",
       " 'see': 105,\n",
       " 'include': 106,\n",
       " 'getting': 107,\n",
       " 'found': 108,\n",
       " 'files': 109,\n",
       " 'change': 110,\n",
       " 'program': 111,\n",
       " 'question': 112,\n",
       " 'variable': 113,\n",
       " 'script': 114,\n",
       " 'doesnt': 115,\n",
       " 'let': 116,\n",
       " 'database': 117,\n",
       " 'form': 118,\n",
       " 'key': 119,\n",
       " 'const': 120,\n",
       " 'used': 121,\n",
       " 'url': 122,\n",
       " 'call': 123,\n",
       " 'different': 124,\n",
       " 'without': 125,\n",
       " 'column': 126,\n",
       " 'works': 127,\n",
       " 'systemoutprintln': 128,\n",
       " 'override': 129,\n",
       " 'build': 130,\n",
       " 'another': 131,\n",
       " 'show': 132,\n",
       " 'char': 133,\n",
       " 'possible': 134,\n",
       " 'however': 135,\n",
       " 'message': 136,\n",
       " 'javascript': 137,\n",
       " 'query': 138,\n",
       " 'cannot': 139,\n",
       " 'write': 140,\n",
       " 'check': 141,\n",
       " 'r': 142,\n",
       " 'command': 143,\n",
       " 'echo': 144,\n",
       " 'f': 145,\n",
       " 'loop': 146,\n",
       " 'start': 147,\n",
       " 'read': 148,\n",
       " 'json': 149,\n",
       " 'running': 150,\n",
       " 'api': 151,\n",
       " 'sql': 152,\n",
       " 'a': 153,\n",
       " 'wrong': 154,\n",
       " 'p': 155,\n",
       " 'row': 156,\n",
       " 'anyone': 157,\n",
       " 'default': 158,\n",
       " 'right': 159,\n",
       " 'size': 160,\n",
       " 'px': 161,\n",
       " 'double': 162,\n",
       " 'request': 163,\n",
       " 'def': 164,\n",
       " 'click': 165,\n",
       " 'printf': 166,\n",
       " 'able': 167,\n",
       " 'item': 168,\n",
       " 'display': 169,\n",
       " 'component': 170,\n",
       " 'simple': 171,\n",
       " 'convert': 172,\n",
       " 'understand': 173,\n",
       " 'access': 174,\n",
       " 'inside': 175,\n",
       " 'count': 176,\n",
       " 'j': 177,\n",
       " 'exception': 178,\n",
       " 'open': 179,\n",
       " 'v': 180,\n",
       " 'path': 181,\n",
       " 'issue': 182,\n",
       " 'studio': 183,\n",
       " 'element': 184,\n",
       " 'multiple': 185,\n",
       " 'go': 186,\n",
       " 'password': 187,\n",
       " 'for': 188,\n",
       " 'created': 189,\n",
       " 'even': 190,\n",
       " 'update': 191,\n",
       " 'index': 192,\n",
       " 'node': 193,\n",
       " 'email': 194,\n",
       " 'install': 195,\n",
       " 'numbers': 196,\n",
       " 'link': 197,\n",
       " 'module': 198,\n",
       " 'every': 199,\n",
       " 'failed': 200,\n",
       " 'solution': 201,\n",
       " 'response': 202,\n",
       " 'order': 203,\n",
       " 'seems': 204,\n",
       " 'still': 205,\n",
       " 'format': 206,\n",
       " 'cout': 207,\n",
       " 'second': 208,\n",
       " 'thank': 209,\n",
       " 'got': 210,\n",
       " 'web': 211,\n",
       " 'angular': 212,\n",
       " 'break': 213,\n",
       " 'last': 214,\n",
       " 'instead': 215,\n",
       " 'react': 216,\n",
       " 'sure': 217,\n",
       " 'google': 218,\n",
       " 'someone': 219,\n",
       " 'consolelog': 220,\n",
       " 'many': 221,\n",
       " 'long': 222,\n",
       " 'context': 223,\n",
       " 'fine': 224,\n",
       " 'answer': 225,\n",
       " 'color': 226,\n",
       " 'l': 227,\n",
       " 'option': 228,\n",
       " 'advance': 229,\n",
       " 'already': 230,\n",
       " 'service': 231,\n",
       " 'insert': 232,\n",
       " 'current': 233,\n",
       " 'next': 234,\n",
       " 'remove': 235,\n",
       " 'source': 236,\n",
       " 'position': 237,\n",
       " 'title': 238,\n",
       " 'description': 239,\n",
       " 'state': 240,\n",
       " 'package': 241,\n",
       " 'correct': 242,\n",
       " 'final': 243,\n",
       " 'post': 244,\n",
       " 'part': 245,\n",
       " 'content': 246,\n",
       " 'word': 247,\n",
       " 'library': 248,\n",
       " 'called': 249,\n",
       " 'given': 250,\n",
       " 'system': 251,\n",
       " 'range': 252,\n",
       " 'info': 253,\n",
       " 'map': 254,\n",
       " 'css': 255,\n",
       " 'put': 256,\n",
       " 'store': 257,\n",
       " 'width': 258,\n",
       " 'search': 259,\n",
       " 'specific': 260,\n",
       " 'pass': 261,\n",
       " 'returns': 262,\n",
       " 'windows': 263,\n",
       " 'field': 264,\n",
       " 'sum': 265,\n",
       " 'this': 266,\n",
       " 'str': 267,\n",
       " 'idea': 268,\n",
       " 'users': 269,\n",
       " 'really': 270,\n",
       " 'must': 271,\n",
       " 'statement': 272,\n",
       " 'information': 273,\n",
       " 'k': 274,\n",
       " 'website': 275,\n",
       " 'results': 276,\n",
       " 'model': 277,\n",
       " 'fix': 278,\n",
       " 'body': 279,\n",
       " 'based': 280,\n",
       " 'difference': 281,\n",
       " 'point': 282,\n",
       " 'args': 283,\n",
       " 'done': 284,\n",
       " 'directory': 285,\n",
       " 'extends': 286,\n",
       " 'height': 287,\n",
       " 'struct': 288,\n",
       " 'looks': 289,\n",
       " 'compile': 290,\n",
       " 'integer': 291,\n",
       " 'expected': 292,\n",
       " 'errors': 293,\n",
       " 'catch': 294,\n",
       " 'username': 295,\n",
       " 'single': 296,\n",
       " 'folder': 297,\n",
       " 'float': 298,\n",
       " 's': 299,\n",
       " 'best': 300,\n",
       " 'property': 301,\n",
       " 'docker': 302,\n",
       " 'delete': 303,\n",
       " 'send': 304,\n",
       " 'event': 305,\n",
       " 'load': 306,\n",
       " 'elements': 307,\n",
       " 'variables': 308,\n",
       " 'give': 309,\n",
       " 'creating': 310,\n",
       " 'h': 311,\n",
       " 'left': 312,\n",
       " 'since': 313,\n",
       " 'hello': 314,\n",
       " 'appreciated': 315,\n",
       " 'currently': 316,\n",
       " 'g': 317,\n",
       " 'length': 318,\n",
       " 'activity': 319,\n",
       " 'contains': 320,\n",
       " 'random': 321,\n",
       " 'say': 322,\n",
       " 'client': 323,\n",
       " 'much': 324,\n",
       " 'login': 325,\n",
       " 'instance': 326,\n",
       " 'syntax': 327,\n",
       " 'functions': 328,\n",
       " 'none': 329,\n",
       " 'objects': 330,\n",
       " 'looking': 331,\n",
       " 'func': 332,\n",
       " 'think': 333,\n",
       " 'container': 334,\n",
       " 'status': 335,\n",
       " 'well': 336,\n",
       " 'process': 337,\n",
       " 'export': 338,\n",
       " 'template': 339,\n",
       " 'columns': 340,\n",
       " 'total': 341,\n",
       " 'val': 342,\n",
       " 'mysql': 343,\n",
       " 'location': 344,\n",
       " 'rows': 345,\n",
       " 'always': 346,\n",
       " 'seem': 347,\n",
       " 'figure': 348,\n",
       " 'address': 349,\n",
       " 'missing': 350,\n",
       " 'back': 351,\n",
       " 'npm': 352,\n",
       " 'js': 353,\n",
       " 'db': 354,\n",
       " 'self': 355,\n",
       " 'err': 356,\n",
       " 'console': 357,\n",
       " 'empty': 358,\n",
       " 'etc': 359,\n",
       " 'reference': 360,\n",
       " 'good': 361,\n",
       " 'boolean': 362,\n",
       " 'num': 363,\n",
       " 'task': 364,\n",
       " 'header': 365,\n",
       " 'connection': 366,\n",
       " 'custom': 367,\n",
       " 'constructor': 368,\n",
       " 'screen': 369,\n",
       " 'visual': 370,\n",
       " 'ios': 371,\n",
       " 'bar': 372,\n",
       " 'intent': 373,\n",
       " 'jquery': 374,\n",
       " 'foo': 375,\n",
       " 'take': 376,\n",
       " 'may': 377,\n",
       " 'within': 378,\n",
       " 'label': 379,\n",
       " 'save': 380,\n",
       " 'whats': 381,\n",
       " 'mean': 382,\n",
       " 'required': 383,\n",
       " 'td': 384,\n",
       " 'textview': 385,\n",
       " 'replace': 386,\n",
       " 'require': 387,\n",
       " 'swift': 388,\n",
       " 'anything': 389,\n",
       " 'lines': 390,\n",
       " 'look': 391,\n",
       " 'log': 392,\n",
       " 'shows': 393,\n",
       " 'items': 394,\n",
       " 'options': 395,\n",
       " 'core': 396,\n",
       " 'warning': 397,\n",
       " 'findviewbyid': 398,\n",
       " 'installed': 399,\n",
       " 'solve': 400,\n",
       " 'via': 401,\n",
       " 'tag': 402,\n",
       " 'top': 403,\n",
       " 'added': 404,\n",
       " 'endl': 405,\n",
       " 'background': 406,\n",
       " 'tell': 407,\n",
       " 'nothing': 408,\n",
       " 'native': 409,\n",
       " 'git': 410,\n",
       " 'match': 411,\n",
       " 'group': 412,\n",
       " 'action': 413,\n",
       " 'gives': 414,\n",
       " 'copy': 415,\n",
       " 'parameter': 416,\n",
       " 'methods': 417,\n",
       " 'define': 418,\n",
       " 'memory': 419,\n",
       " 'root': 420,\n",
       " 'keep': 421,\n",
       " 'http': 422,\n",
       " 'far': 423,\n",
       " 'ie': 424,\n",
       " 'vs': 425,\n",
       " 'defined': 426,\n",
       " 'images': 427,\n",
       " 'lot': 428,\n",
       " 'everything': 429,\n",
       " 'child': 430,\n",
       " 'better': 431,\n",
       " 'eg': 432,\n",
       " 'thing': 433,\n",
       " 'names': 434,\n",
       " 'bit': 435,\n",
       " 'character': 436,\n",
       " 'local': 437,\n",
       " 'times': 438,\n",
       " 'implement': 439,\n",
       " 'unable': 440,\n",
       " 'token': 441,\n",
       " 'explain': 442,\n",
       " 'regex': 443,\n",
       " 'documentation': 444,\n",
       " 'window': 445,\n",
       " 'similar': 446,\n",
       " 'execute': 447,\n",
       " 'parent': 448,\n",
       " 'going': 449,\n",
       " 'didnt': 450,\n",
       " 'strings': 451,\n",
       " 'net': 452,\n",
       " 'head': 453,\n",
       " 'invalid': 454,\n",
       " 'implementation': 455,\n",
       " 'connect': 456,\n",
       " 'made': 457,\n",
       " 'namespace': 458,\n",
       " 'sort': 459,\n",
       " 'd': 460,\n",
       " 'note': 461,\n",
       " 'undefined': 462,\n",
       " 'protected': 463,\n",
       " 'reason': 464,\n",
       " 'arraylist': 465,\n",
       " 'thread': 466,\n",
       " 'switch': 467,\n",
       " 'configuration': 468,\n",
       " 'words': 469,\n",
       " 'stack': 470,\n",
       " 'interface': 471,\n",
       " 'changes': 472,\n",
       " 'adding': 473,\n",
       " 'day': 474,\n",
       " 'classes': 475,\n",
       " 'browser': 476,\n",
       " 'block': 477,\n",
       " 'menu': 478,\n",
       " 'bool': 479,\n",
       " 'join': 480,\n",
       " 'savedinstancestate': 481,\n",
       " 'says': 482,\n",
       " 'vector': 483,\n",
       " 'dataframe': 484,\n",
       " 'expression': 485,\n",
       " 'bundle': 486,\n",
       " 'available': 487,\n",
       " 'game': 488,\n",
       " 'either': 489,\n",
       " 'style': 490,\n",
       " 'debug': 491,\n",
       " 'operator': 492,\n",
       " 'achieve': 493,\n",
       " 'device': 494,\n",
       " 'structure': 495,\n",
       " 'w': 496,\n",
       " 'heres': 497,\n",
       " 'year': 498,\n",
       " 'characters': 499,\n",
       " 'making': 500,\n",
       " 'box': 501,\n",
       " 'site': 502,\n",
       " 'actually': 503,\n",
       " 'isnt': 504,\n",
       " 'ok': 505,\n",
       " 'base': 506,\n",
       " 'started': 507,\n",
       " 'generate': 508,\n",
       " 'pointer': 509,\n",
       " 'around': 510,\n",
       " 'controller': 511,\n",
       " 'price': 512,\n",
       " 'types': 513,\n",
       " 'valid': 514,\n",
       " 'xml': 515,\n",
       " 'fields': 516,\n",
       " 'max': 517,\n",
       " 'argument': 518,\n",
       " 'temp': 519,\n",
       " 'chrome': 520,\n",
       " 'things': 521,\n",
       " 'plugin': 522,\n",
       " 'tostring': 523,\n",
       " 'resolve': 524,\n",
       " 'target': 525,\n",
       " 'product': 526,\n",
       " 'exit': 527,\n",
       " 'scanner': 528,\n",
       " 'questions': 529,\n",
       " 'language': 530,\n",
       " 'parameters': 531,\n",
       " 'three': 532,\n",
       " 'exist': 533,\n",
       " 'y': 534,\n",
       " 'step': 535,\n",
       " 'dependency': 536,\n",
       " 't': 537,\n",
       " 'li': 538,\n",
       " 'z': 539,\n",
       " 'xcode': 540,\n",
       " 'filename': 541,\n",
       " 'u': 542,\n",
       " 'gets': 543,\n",
       " 'amount': 544,\n",
       " 'dependencies': 545,\n",
       " 'split': 546,\n",
       " 'firebase': 547,\n",
       " 'setting': 548,\n",
       " 'environment': 549,\n",
       " 'document': 550,\n",
       " 'cell': 551,\n",
       " 'filter': 552,\n",
       " 'showing': 553,\n",
       " 'tr': 554,\n",
       " 'foreach': 555,\n",
       " 'correctly': 556,\n",
       " 'age': 557,\n",
       " 'excel': 558,\n",
       " 'q': 559,\n",
       " 'writing': 560,\n",
       " 'typescript': 561,\n",
       " 'alert': 562,\n",
       " 'condition': 563,\n",
       " 'space': 564,\n",
       " 'month': 565,\n",
       " 'uses': 566,\n",
       " 'full': 567,\n",
       " 'lets': 568,\n",
       " 'support': 569,\n",
       " 'while': 570,\n",
       " 'move': 571,\n",
       " 'account': 572,\n",
       " 'programming': 573,\n",
       " 'yes': 574,\n",
       " 'handle': 575,\n",
       " 'the': 576,\n",
       " 'config': 577,\n",
       " 'learning': 578,\n",
       " 'basic': 579,\n",
       " 'selected': 580,\n",
       " 'dictionary': 581,\n",
       " 'consolewriteline': 582,\n",
       " 'written': 583,\n",
       " 'init': 584,\n",
       " 'takes': 585,\n",
       " 'changed': 586,\n",
       " 'reading': 587,\n",
       " 'wondering': 588,\n",
       " 'details': 589,\n",
       " 'apply': 590,\n",
       " 'framework': 591,\n",
       " 'starting': 592,\n",
       " 'render': 593,\n",
       " 'sample': 594,\n",
       " 'global': 595,\n",
       " 'properties': 596,\n",
       " 'arrays': 597,\n",
       " 'df': 598,\n",
       " 'frame': 599,\n",
       " 'thats': 600,\n",
       " 'level': 601,\n",
       " 'throws': 602,\n",
       " 'spring': 603,\n",
       " 'place': 604,\n",
       " 'might': 605,\n",
       " 'section': 606,\n",
       " 'calling': 607,\n",
       " 'varchar': 608,\n",
       " 'tests': 609,\n",
       " 'player': 610,\n",
       " 'sub': 611,\n",
       " 'aws': 612,\n",
       " 'side': 613,\n",
       " 'push': 614,\n",
       " 'csv': 615,\n",
       " 'auto': 616,\n",
       " 'kind': 617,\n",
       " 'attribute': 618,\n",
       " 'fragment': 619,\n",
       " 'port': 620,\n",
       " 'maybe': 621,\n",
       " 'provide': 622,\n",
       " 'setup': 623,\n",
       " 'building': 624,\n",
       " 'linux': 625,\n",
       " 'layout': 626,\n",
       " 'certain': 627,\n",
       " 'contain': 628,\n",
       " 'host': 629,\n",
       " 'success': 630,\n",
       " 'len': 631,\n",
       " 'download': 632,\n",
       " 'days': 633,\n",
       " 'aspnet': 634,\n",
       " 'pattern': 635,\n",
       " 'close': 636,\n",
       " 'unknown': 637,\n",
       " 'stored': 638,\n",
       " 'ideas': 639,\n",
       " 'video': 640,\n",
       " 'nil': 641,\n",
       " 'though': 642,\n",
       " 'needs': 643,\n",
       " 'automatically': 644,\n",
       " 'fetch': 645,\n",
       " 'points': 646,\n",
       " 'named': 647,\n",
       " 'seconds': 648,\n",
       " 'properly': 649,\n",
       " 'activitythreadjava': 650,\n",
       " 'sender': 651,\n",
       " 'entry': 652,\n",
       " 'in': 653,\n",
       " 'edittext': 654,\n",
       " 'exactly': 655,\n",
       " 'tables': 656,\n",
       " 'whole': 657,\n",
       " 'phone': 658,\n",
       " 'machine': 659,\n",
       " 'exists': 660,\n",
       " 'checked': 661,\n",
       " 'documentgetelementbyid': 662,\n",
       " 'parse': 663,\n",
       " 'means': 664,\n",
       " 'route': 665,\n",
       " 'testing': 666,\n",
       " 'compiler': 667,\n",
       " 'per': 668,\n",
       " 'person': 669,\n",
       " 'approach': 670,\n",
       " 'score': 671,\n",
       " 'components': 672,\n",
       " 'rest': 673,\n",
       " 'play': 674,\n",
       " 'mode': 675,\n",
       " 'onclick': 676,\n",
       " 'student': 677,\n",
       " 'couldnt': 678,\n",
       " 'allow': 679,\n",
       " 'hi': 680,\n",
       " 'arr': 681,\n",
       " 'datetime': 682,\n",
       " 'basically': 683,\n",
       " 'services': 684,\n",
       " 'async': 685,\n",
       " 'counter': 686,\n",
       " 'center': 687,\n",
       " 'successfully': 688,\n",
       " 'wont': 689,\n",
       " 'whether': 690,\n",
       " 'control': 691,\n",
       " 'flutter': 692,\n",
       " 'red': 693,\n",
       " 'extract': 694,\n",
       " 'ip': 695,\n",
       " 'standard': 696,\n",
       " 'stop': 697,\n",
       " 'nested': 698,\n",
       " 'calculate': 699,\n",
       " 'col': 700,\n",
       " 'runs': 701,\n",
       " 'br': 702,\n",
       " 'clear': 703,\n",
       " 'network': 704,\n",
       " 'generated': 705,\n",
       " 'wanted': 706,\n",
       " 'os': 707,\n",
       " 'keys': 708,\n",
       " 'compare': 709,\n",
       " 'sizeof': 710,\n",
       " 'headers': 711,\n",
       " 'webpack': 712,\n",
       " 'simply': 713,\n",
       " 'development': 714,\n",
       " 'several': 715,\n",
       " 'pandas': 716,\n",
       " 'previous': 717,\n",
       " 'span': 718,\n",
       " 'old': 719,\n",
       " 'updated': 720,\n",
       " 'loading': 721,\n",
       " 'thought': 722,\n",
       " 'never': 723,\n",
       " 'matrix': 724,\n",
       " 'abc': 725,\n",
       " 'settings': 726,\n",
       " 'session': 727,\n",
       " 'ask': 728,\n",
       " 'complete': 729,\n",
       " 'separate': 730,\n",
       " 'elif': 731,\n",
       " 'img': 732,\n",
       " 'follows': 733,\n",
       " 'packages': 734,\n",
       " 'apps': 735,\n",
       " 'userid': 736,\n",
       " 'dynamic': 737,\n",
       " 'expect': 738,\n",
       " 'shown': 739,\n",
       " 'res': 740,\n",
       " 'changing': 741,\n",
       " 'makes': 742,\n",
       " 'std': 743,\n",
       " 'begin': 744,\n",
       " 'laravel': 745,\n",
       " 'nodejs': 746,\n",
       " 'record': 747,\n",
       " 'arguments': 748,\n",
       " 'extension': 749,\n",
       " 'icon': 750,\n",
       " 'min': 751,\n",
       " 'loaded': 752,\n",
       " 'ms': 753,\n",
       " 'home': 754,\n",
       " 'yet': 755,\n",
       " 'tab': 756,\n",
       " 'particular': 757,\n",
       " 'operation': 758,\n",
       " 'learn': 759,\n",
       " 'virtual': 760,\n",
       " 'world': 761,\n",
       " 'letter': 762,\n",
       " 'small': 763,\n",
       " 'seen': 764,\n",
       " 'active': 765,\n",
       " 'mobile': 766,\n",
       " 'bottom': 767,\n",
       " 'problems': 768,\n",
       " 'resource': 769,\n",
       " 'requests': 770,\n",
       " 'feature': 771,\n",
       " 'upload': 772,\n",
       " 'little': 773,\n",
       " 'edit': 774,\n",
       " 'bootstrap': 775,\n",
       " 'byte': 776,\n",
       " 'buttons': 777,\n",
       " 'people': 778,\n",
       " 'oncreate': 779,\n",
       " 'come': 780,\n",
       " 'present': 781,\n",
       " 'ajax': 782,\n",
       " 'guess': 783,\n",
       " 'grid': 784,\n",
       " 'except': 785,\n",
       " 'stream': 786,\n",
       " 'lambda': 787,\n",
       " 'existing': 788,\n",
       " 'related': 789,\n",
       " 'book': 790,\n",
       " 'unique': 791,\n",
       " 'kotlin': 792,\n",
       " 'stuck': 793,\n",
       " 'equal': 794,\n",
       " 'remote': 795,\n",
       " 'category': 796,\n",
       " 'sorry': 797,\n",
       " 'worked': 798,\n",
       " 'fails': 799,\n",
       " 'directly': 800,\n",
       " 'examples': 801,\n",
       " 'super': 802,\n",
       " 'original': 803,\n",
       " 'easy': 804,\n",
       " 'online': 805,\n",
       " 'calls': 806,\n",
       " 'ul': 807,\n",
       " 'lists': 808,\n",
       " 'scanf': 809,\n",
       " 'ubuntu': 810,\n",
       " 'job': 811,\n",
       " 'giving': 812,\n",
       " 'hours': 813,\n",
       " 'returned': 814,\n",
       " 'theres': 815,\n",
       " 'throw': 816,\n",
       " 'dim': 817,\n",
       " 'happens': 818,\n",
       " 'records': 819,\n",
       " 'declare': 820,\n",
       " 'bad': 821,\n",
       " 'ui': 822,\n",
       " 'manually': 823,\n",
       " 'appears': 824,\n",
       " 'firstname': 825,\n",
       " 'logic': 826,\n",
       " 'according': 827,\n",
       " 'stuff': 828,\n",
       " 'submit': 829,\n",
       " 'symbol': 830,\n",
       " 'unexpected': 831,\n",
       " 'unit': 832,\n",
       " 'binary': 833,\n",
       " 'normal': 834,\n",
       " 'na': 835,\n",
       " 'release': 836,\n",
       " 'es': 837,\n",
       " 'disable': 838,\n",
       " 'continue': 839,\n",
       " 'needed': 840,\n",
       " 'font': 841,\n",
       " 'actual': 842,\n",
       " 'member': 843,\n",
       " 'appear': 844,\n",
       " 'regular': 845,\n",
       " 'decimal': 846,\n",
       " 'understanding': 847,\n",
       " 'duplicate': 848,\n",
       " 'issues': 849,\n",
       " 'large': 850,\n",
       " 'specified': 851,\n",
       " 'gradle': 852,\n",
       " 'github': 853,\n",
       " 'obj': 854,\n",
       " 'answers': 855,\n",
       " 'ex': 856,\n",
       " 'docs': 857,\n",
       " 'txt': 858,\n",
       " 'passed': 859,\n",
       " 'computer': 860,\n",
       " 'assign': 861,\n",
       " 'due': 862,\n",
       " 'prints': 863,\n",
       " 'goes': 864,\n",
       " 'white': 865,\n",
       " 'tutorial': 866,\n",
       " 'repository': 867,\n",
       " 'comes': 868,\n",
       " 'quite': 869,\n",
       " 'admin': 870,\n",
       " 'codes': 871,\n",
       " 'merge': 872,\n",
       " 'external': 873,\n",
       " 'django': 874,\n",
       " 'await': 875,\n",
       " 'primary': 876,\n",
       " 'sheet': 877,\n",
       " 'listview': 878,\n",
       " 'less': 879,\n",
       " 'coding': 880,\n",
       " 'it': 881,\n",
       " 'ruby': 882,\n",
       " 'course': 883,\n",
       " 'picture': 884,\n",
       " 'returning': 885,\n",
       " 'lastname': 886,\n",
       " 'messages': 887,\n",
       " 'guys': 888,\n",
       " 'pretty': 889,\n",
       " 'th': 890,\n",
       " 'padding': 891,\n",
       " 'choice': 892,\n",
       " 'links': 893,\n",
       " 'perform': 894,\n",
       " 'appreciate': 895,\n",
       " 'great': 896,\n",
       " 'hash': 897,\n",
       " 'free': 898,\n",
       " 'commands': 899,\n",
       " 'trouble': 900,\n",
       " 'projects': 901,\n",
       " 'behavior': 902,\n",
       " 'latest': 903,\n",
       " 'average': 904,\n",
       " 'navigation': 905,\n",
       " 'avoid': 906,\n",
       " 'mac': 907,\n",
       " 'algorithm': 908,\n",
       " 'passing': 909,\n",
       " 'limit': 910,\n",
       " 'real': 911,\n",
       " 'branch': 912,\n",
       " 'sequence': 913,\n",
       " 'unsigned': 914,\n",
       " 'clicked': 915,\n",
       " 'hide': 916,\n",
       " 'suggest': 917,\n",
       " 'retrieve': 918,\n",
       " 'props': 919,\n",
       " 'modules': 920,\n",
       " 'confused': 921,\n",
       " 'notification': 922,\n",
       " 'sdk': 923,\n",
       " 'internet': 924,\n",
       " 'numpy': 925,\n",
       " 'choose': 926,\n",
       " 'outside': 927,\n",
       " 'big': 928,\n",
       " 'pages': 929,\n",
       " 'redirect': 930,\n",
       " 'suggestions': 931,\n",
       " 'recent': 932,\n",
       " 'press': 933,\n",
       " 'runtime': 934,\n",
       " 'typeerror': 935,\n",
       " 'hope': 936,\n",
       " 'recently': 937,\n",
       " 'design': 938,\n",
       " 'cin': 939,\n",
       " 'ch': 940,\n",
       " 'or': 941,\n",
       " 'widget': 942,\n",
       " 'ts': 943,\n",
       " 'versions': 944,\n",
       " 'card': 945,\n",
       " 'entered': 946,\n",
       " 'employee': 947,\n",
       " 'collection': 948,\n",
       " 'inputs': 949,\n",
       " 'authentication': 950,\n",
       " 'append': 951,\n",
       " 'beginner': 952,\n",
       " 'bytes': 953,\n",
       " 'de': 954,\n",
       " 'wrote': 955,\n",
       " 'least': 956,\n",
       " 'performance': 957,\n",
       " 'across': 958,\n",
       " 'stdcout': 959,\n",
       " 'ways': 960,\n",
       " 'callback': 961,\n",
       " 'containing': 962,\n",
       " 'inner': 963,\n",
       " 'area': 964,\n",
       " 'receive': 965,\n",
       " 'cache': 966,\n",
       " 'requires': 967,\n",
       " 'attempt': 968,\n",
       " 'rather': 969,\n",
       " 'children': 970,\n",
       " 'bash': 971,\n",
       " 'execution': 972,\n",
       " 'tree': 973,\n",
       " 'assignment': 974,\n",
       " 'localhost': 975,\n",
       " 'solutions': 976,\n",
       " 'supposed': 977,\n",
       " 'fun': 978,\n",
       " 'happening': 979,\n",
       " 'definition': 980,\n",
       " 'letters': 981,\n",
       " 'cloud': 982,\n",
       " 'imageview': 983,\n",
       " 'common': 984,\n",
       " 'provided': 985,\n",
       " 'dev': 986,\n",
       " 'tools': 987,\n",
       " 'displayed': 988,\n",
       " 'country': 989,\n",
       " 'scroll': 990,\n",
       " 'ab': 991,\n",
       " 'modify': 992,\n",
       " 'which': 993,\n",
       " 'adapter': 994,\n",
       " 'flag': 995,\n",
       " 'pip': 996,\n",
       " 'us': 997,\n",
       " 'not': 998,\n",
       " 'searching': 999,\n",
       " 'm': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 6926 words (3073 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt at using glove 6B 200 embeddings, and use those for training. Main problem resides in the fact that the vocabulary for the embeddings does not correspond well with the dataset being used. Probably because Stack Overflow questions include very technical language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19618   ,  0.54193002,  0.44931   , ...,  0.56757998,\n",
       "         0.24089   , -0.033112  ],\n",
       "       [-0.013127  ,  0.082789  , -0.02023   , ...,  0.21653   ,\n",
       "         0.0048408 ,  0.55470002],\n",
       "       [-0.13451999,  0.42318001, -0.20051999, ..., -0.0091233 ,\n",
       "         0.31496999,  0.47435999],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False, input_length = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, None, 200)         10000200  \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               120400    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 10,147,227\n",
      "Trainable params: 147,027\n",
      "Non-trainable params: 10,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.SpatialDropout1D(0.3)(embedded_sequences)\n",
    "x = layers.LSTM(100, recurrent_dropout= 0.25, dropout = 0.25)(embedded_sequences)\n",
    "x = layers.Dense(256, activation = 'relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 95,  23,  40, ...,   0,   0,   0],\n",
       "       [ 14,   4, 328, ...,   0,   0,   0],\n",
       "       [ 14,  34,  54, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 14,   4, 331, ...,   0,   0,   0],\n",
       "       [824,  16, 407, ...,   0,   0,   0],\n",
       "       [515,   4, 329, ...,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam=tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "54000/54000 [==============================] - 12s 226us/sample - loss: 1.0944 - accuracy: 0.3486 - val_loss: 1.0929 - val_accuracy: 0.3555\n",
      "Epoch 2/100\n",
      "54000/54000 [==============================] - 10s 192us/sample - loss: 1.0940 - accuracy: 0.3491 - val_loss: 1.0927 - val_accuracy: 0.3558\n",
      "Epoch 3/100\n",
      "54000/54000 [==============================] - 10s 194us/sample - loss: 1.0935 - accuracy: 0.3541 - val_loss: 1.0925 - val_accuracy: 0.3562\n",
      "Epoch 4/100\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 1.0935 - accuracy: 0.3516 - val_loss: 1.0923 - val_accuracy: 0.3570\n",
      "Epoch 5/100\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 1.0933 - accuracy: 0.3539 - val_loss: 1.0922 - val_accuracy: 0.3568\n",
      "Epoch 6/100\n",
      "54000/54000 [==============================] - 10s 194us/sample - loss: 1.0930 - accuracy: 0.3525 - val_loss: 1.0921 - val_accuracy: 0.3572\n",
      "Epoch 7/100\n",
      "54000/54000 [==============================] - 11s 196us/sample - loss: 1.0932 - accuracy: 0.3535 - val_loss: 1.0920 - val_accuracy: 0.3570\n",
      "Epoch 8/100\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 1.0930 - accuracy: 0.3546 - val_loss: 1.0919 - val_accuracy: 0.3570\n",
      "Epoch 9/100\n",
      "54000/54000 [==============================] - 10s 194us/sample - loss: 1.0928 - accuracy: 0.3523 - val_loss: 1.0918 - val_accuracy: 0.3573\n",
      "Epoch 10/100\n",
      "54000/54000 [==============================] - 11s 196us/sample - loss: 1.0926 - accuracy: 0.3558 - val_loss: 1.0917 - val_accuracy: 0.3572\n",
      "Epoch 11/100\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 1.0925 - accuracy: 0.3555 - val_loss: 1.0916 - val_accuracy: 0.3570\n",
      "Epoch 12/100\n",
      "54000/54000 [==============================] - 10s 193us/sample - loss: 1.0925 - accuracy: 0.3547 - val_loss: 1.0916 - val_accuracy: 0.3567\n",
      "Epoch 13/100\n",
      "54000/54000 [==============================] - 11s 196us/sample - loss: 1.0923 - accuracy: 0.3552 - val_loss: 1.0915 - val_accuracy: 0.3570\n",
      "Epoch 14/100\n",
      "54000/54000 [==============================] - 11s 195us/sample - loss: 1.0923 - accuracy: 0.3557 - val_loss: 1.0914 - val_accuracy: 0.3570\n",
      "Epoch 15/100\n",
      " 6144/54000 [==>...........................] - ETA: 8s - loss: 1.0918 - accuracy: 0.3608"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-608-879fe907d8b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adagrad'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m )\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer='adagrad', metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=2048, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is stopped due to poor performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
