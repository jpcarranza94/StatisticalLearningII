{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breve resumen de paper original sobre Convolutional Neural Networks escrito por Yann LeCun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales convolucionales fueron creadas por el investigador, ahora ganador del Premio Turing por sus aportes en el campo de Deep Learning en los 90s. Un paper en específico que describía la utilidad de utilizar convoluciones para entrenar redes neuronales que fueran útiles en el ámbito de computer vision. A continuación están algunos de los puntos importantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La convolución aplicada al mundo de computer vision, o correlación cruzada en el mundo de matemáticas es una operación que permite encontra como se comporta una función en relación a otra función. Es básicamente la aplicación de un filtro sobre una imagen, en el ámbito de computer vision.\n",
    "\n",
    "Por muchos años, los pesos de los filtros, o kernels han sido diseñados de manera manual para poder extraer la información relevante de la imagen. (Filtro de Sobel, filtro de Laplace, por ejemplo). Sin embargo, el autor Yann LeCun propone el uso de backpropagation para entrenar los pesos de estos filtros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspiración biológica\n",
    "\n",
    "Algunos experimentos realizados durante los años 60s que postulaban una teoría de cómo la visión de mamíferos funciona fueron de especial inspiración para el autor. La idea principal es de que diferentes capas de neuronas extraen características importantes de la imagen, estas características empiezan siendo de muy bajo nivel y básicas (como orientación de líneas rectas). Posteriormente las características extraídas son más complejas y abstractas, a manera de que al final de varias capas se logra discernir qué objeto se está observando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "A pesar de que esta idea era conocida y se trató de aplicar por autores como Fukushima con su Neurocognitron en los 80s, ningún algoritmo de optimización había permito entrenar estos modelos. Yann LeCun logra implementar backpropagation a manera de que se puedan entrenar los kernels de los pesos utilizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"backprop.jpeg\">\n",
    "\n",
    "Créditos a 3Blue1Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventajas del uso de convoluciones\n",
    "\n",
    "Las convoluciones permiten la extracción de características de manera automática, sin necesidad de que un humano diseñe los kernels, ya que estos pueden ser aprendidos a través de backpropagation.\n",
    "\n",
    "Además de esta razón, una de las principales mejoras es que los kernels son pesos compartidos entre cada capa. De esta manera se puede detectar la misma característica independientemente de la posición que tenga en la imagen. Esto además reduce grandemente la cantidad conexiones entre una capa y la siguiente. Es por esto que se dice que las redes neuronales convolucionales tienen *sparse connections*.\n",
    "\n",
    "<img src=\"convolucion.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de esto, Yann Lecun también teoriza sobre el uso de Pooling para poder hacer el modelo más resistente a ciertas rotaciones o traslaciones pequeñas que pueden haber dentro del receptive field.\n",
    "\n",
    "<img src= \"M\n",
    "\n",
    "\n",
    "\n",
    "El resultado de esto es que el modelo imeplementado por LeCun permitía realizar reconocimiento de dígitos de manera bastante exacta, e indepentemente de su posición en la imagen utilizada. Esto fue un gran avance en el campo de visión por computadora. Sin embargo, el uso de redes neuronales fue muy poco hasta el acontecimiento en el que el equipo de la Universidad de Toronto liderado por Hinton desarrolló AlexNet para obtener resultados un 10% mejores que los mejores modelos de computer vision de esa época."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
