{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-propagation (Práctica)\n",
    "\n",
    "Entrenar un aproximador para la función XOR usando 2 capas intermedias.\n",
    "* Usar 2 neuronas en la capa anterior a la salida (segunda capa oculta=\n",
    "* Usar al menos 2( pueden ser más) en la primera capa oculta.\n",
    "* Usar activación ReLU en las capas intermedias y no activación en la salida\n",
    "\n",
    "Usar Numpy.\n",
    "\n",
    "Realizar 5 experimentos, en cada experimento (corrida de entrenamiento):\n",
    "* Inicializar los parámetros aleatoriamente con distribución normal centrada en 0 y std = 0.1\n",
    "* Retornar la representación intermedia de la segunda capa oculta.\n",
    "\n",
    "Graficar las 5 representaciones intermedias, comparar, comentar y/o concluir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return np.maximum(0,X) \n",
    "\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def derivative_relu(array):\n",
    "    return np.array([n > 0 for n in array], dtype = np.int)\n",
    "\n",
    "def softplus(X):\n",
    "    return np.log(1 + np.exp(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetXOR:\n",
    "    def __init__(self, X, y_real):\n",
    "        self.X = X\n",
    "        self.y_real = y_real\n",
    "        self.w_1 = np.random.normal(0, 0.1, (5,3))\n",
    "        self.w_2 = np.random.normal(0, 0.1, (2,6))\n",
    "        self.w_3 = np.random.normal(0, 0.1, (1,3))\n",
    "        \n",
    "    def forward_propagation(self):\n",
    "        X_input = np.append(np.ones((self.X.shape[0], 1)), self.X, axis = -1)\n",
    "        l1 = np.matmul(X_input, self.w_1.T)\n",
    "        l1_a = relu(l1)\n",
    "      \n",
    "        l1_a_w_bias = np.append(np.ones((l1_a.shape[0], 1)),l1_a, axis = -1)\n",
    "        \n",
    "        l2 = np.matmul(l1_a_w_bias, self.w_2.T)\n",
    "        l2_a = relu(l2)\n",
    "       \n",
    "        l2_a_w_bias = np.append(np.ones((l2_a.shape[0], 1)), l2_a, axis = -1 )\n",
    "        \n",
    "        output = np.matmul(l2_a_w_bias, self.w_3.T)\n",
    "        output_a = sigmoid(output)\n",
    "        \n",
    "        return l1, l1_a, l2, l2_a, output, output_a\n",
    "    \n",
    "    def error(self):\n",
    "        _,_,_,_,_,output = self.forward_propagation()\n",
    "        \n",
    "        cross_entropy = -1 * np.mean(y_real * (np.log(output)) + (1 - y_real) * (np.log(1 - output)))\n",
    "        \n",
    "        \n",
    "        return cross_entropy\n",
    "    \n",
    "    def back_prop(self):\n",
    "        error = self.error()\n",
    "        l1, l1_a, l2, l2_a, output, output_a = self.forward_propagation()\n",
    "        d_error_d_output = (output_a - y_real)\n",
    "        d_error_d_w_3 = np.matmul(l2_a.T,d_error_d_output)\n",
    "        d_error_d_l2 =  np.matmul(d_error_d_output, self.w_3[:,1:]) * derivative_relu(l2)\n",
    "        d_error_d_w_2 = np.matmul(l1_a.T,d_error_d_l2)\n",
    "        d_error_d_l1 = np.matmul(d_error_d_l2,self.w_2[:,1:]) * derivative_relu(l1)\n",
    "        d_error_d_w_1 = np.matmul(self.X.T,d_error_d_l1)\n",
    "        d_error_b_3 = np.sum(d_error_d_output, axis = 0, keepdims =True)\n",
    "        d_error_b_2 = np.sum(d_error_d_l2, axis = 0, keepdims = True)\n",
    "        d_error_b_1 = np.sum(d_error_d_l1, axis = 0, keepdims = True)        \n",
    "        \n",
    "        return d_error_d_w_3, d_error_d_w_2, d_error_d_w_1, d_error_b_3, d_error_b_2, d_error_b_1\n",
    "    \n",
    "    def fit(self, lr, epochs):\n",
    "        print(\"initial error: \" + str(self.error()))\n",
    "        for i in range(0, epochs):\n",
    "            d_w_3, d_w_2, d_w_1, d_b_3, d_b_2, d_b_1 = self.back_prop()\n",
    "            self.w_3[:,:1] = self.w_3[:,:1][0] - (lr * d_b_3[0])\n",
    "            self.w_3[:,1:] = self.w_3[:,1:][0] - (lr * d_w_3[0])\n",
    "            self.w_2[:,:1] = (self.w_2[:,:1].reshape(1,-1) - (lr * d_b_2)).reshape(-1,1)\n",
    "            self.w_2[:,1:] = self.w_2[:,1:] - lr * d_w_2\n",
    "            self.w_1[:,:1] = (self.w_1[:,:1].reshape(1,-1) - (lr * d_b_2)).reshape(-1,1)\n",
    "            self.w_1[:,1:] = self.w_1[:,1:] - lr * d_w_3\n",
    "            if i%1 == 0:\n",
    "                print(\"Epoch \" + str(i) + \": \" + str(self.error()))\n",
    "            \n",
    "    def predict(self):\n",
    "        _,_,_,_,_,output = self.forward_propagation()\n",
    "        \n",
    "        predictions = np.array([n > 0.5 for n in output], dtype = np.int)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetXOR:\n",
    "    def __init__(self, X, y_real):\n",
    "        self.X = X\n",
    "        self.y_real = y_real\n",
    "        self.w_1 = np.random.normal(0, 1, (2,3))\n",
    "        self.w_2 = np.random.normal(0, 1, (2,3))\n",
    "        self.w_3 = np.random.normal(0, 1, (1,3))\n",
    "        \n",
    "    def forward_propagation(self):\n",
    "        X_input = np.append(np.ones((self.X.shape[0], 1)), self.X, axis = -1)\n",
    "        l1 = np.matmul(X_input, self.w_1.T)\n",
    "        l1_a = softplus(l1)\n",
    "      \n",
    "        l1_a_w_bias = np.append(np.ones((l1_a.shape[0], 1)),l1_a, axis = -1)\n",
    "        l2 = np.matmul(l1_a_w_bias, self.w_2.T)\n",
    "        l2_a = softplus(l2)\n",
    "       \n",
    "        l2_a_w_bias = np.append(np.ones((l2_a.shape[0], 1)), l2_a, axis = -1 )\n",
    "        \n",
    "        output = np.matmul(l2_a_w_bias, self.w_3.T)\n",
    "        output_a = sigmoid(output)\n",
    "        \n",
    "        return l1, l1_a, l2, l2_a, output, output_a\n",
    "    \n",
    "    def error(self):\n",
    "        _,_,_,_,_,output = self.forward_propagation()\n",
    "        \n",
    "        #cross_entropy = -1 * 1/8(self.y_real * (np.log(output)) + (1 - self.y_real) * (np.log(1 - output)))\n",
    "        \n",
    "        MSE = np.squeeze(1/8*(np.sum(np.square(self.y_real - self.predict()))))\n",
    "        \n",
    "        return MSE\n",
    "    \n",
    "    def back_prop(self):\n",
    "        error = self.error()\n",
    "        l1, l1_a, l2, l2_a, output, output_a = self.forward_propagation()\n",
    "        d_error_d_output =  (-1/4 *(y_real - output_a))*(output_a * (1 - output_a))\n",
    "        d_error_d_w_3 = np.matmul(l2_a.T,d_error_d_output)\n",
    "        d_error_d_l2 =  np.matmul(d_error_d_output, self.w_3[:,1:]) * sigmoid(l2)\n",
    "        d_error_d_w_2 = np.matmul(l1_a.T,d_error_d_l2)\n",
    "        d_error_d_l1 = np.matmul(d_error_d_l2,self.w_2[:,1:]) * sigmoid(l1)\n",
    "        d_error_d_w_1 = np.matmul(self.X.T,d_error_d_l1)\n",
    "        d_error_b_3 = np.sum(d_error_d_output, axis = 0, keepdims =True)\n",
    "        d_error_b_2 = np.sum(d_error_d_l2, axis = 0, keepdims = True)\n",
    "        d_error_b_1 = np.sum(d_error_d_l1, axis = 0, keepdims = True)        \n",
    "        \n",
    "        return d_error_d_w_3, d_error_d_w_2, d_error_d_w_1, d_error_b_3, d_error_b_2, d_error_b_1\n",
    "    \n",
    "    def fit(self, lr, epochs):\n",
    "        print(\"initial error: \" + str(self.error()))\n",
    "        for i in range(0, epochs):\n",
    "            d_w_3, d_w_2, d_w_1, d_b_3, d_b_2, d_b_1 = self.back_prop()\n",
    "            self.w_3[:,:1] = self.w_3[:,:1][0] - (lr * d_b_3[0])\n",
    "            self.w_3[:,1:3] = self.w_3[:,1:][0] - (lr * d_w_3[0])\n",
    "            self.w_2[:,:1] = (self.w_2[:,:1].reshape(1,-1) - (lr * d_b_2)).reshape(-1,1)\n",
    "            self.w_2[:,1:3] = self.w_2[:,1:] - lr * d_w_2\n",
    "            self.w_1[:,:1] = (self.w_1[:,:1].reshape(1,-1) - (lr * d_b_2)).reshape(-1,1)\n",
    "            self.w_1[:,1:3] = self.w_1[:,1:] - lr * d_w_3\n",
    "            if i%10000 == 0:\n",
    "                print(\"Epoch \" + str(i) + \": \" + str(self.error()))\n",
    "            \n",
    "    def predict(self):\n",
    "        _,_,_,_,_,output = self.forward_propagation()\n",
    "        \n",
    "        predictions = np.array([n > 0.5 for n in output], dtype = np.int)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inputs = np.array([[0,0], [0,1], [1,0], [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3168,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetXOR(X_inputs, y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10552497,  0.05421978, -0.16167337],\n",
       "       [-0.03901832,  0.1581707 ,  0.07542578],\n",
       "       [-0.13402289, -0.11917437,  0.03019825],\n",
       "       [-0.11033598, -0.11135892,  0.00417707],\n",
       "       [-0.04753658, -0.06248371, -0.019472  ]])"
      ]
     },
     "execution_count": 3169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.w_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.10552497, -0.03901832, -0.13402289, -0.11033598, -0.04753658],\n",
       "        [-0.26719834,  0.03640746, -0.10382464, -0.10615891, -0.06700858],\n",
       "        [-0.05130519,  0.11915238, -0.25319726, -0.22169489, -0.11002029],\n",
       "        [-0.21297857,  0.19457815, -0.22299901, -0.21751783, -0.12949229]]),\n",
       " array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.03640746, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.11915238, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.19457815, 0.        , 0.        , 0.        ]]),\n",
       " array([[ 0.00245438, -0.0061506 ],\n",
       "        [ 0.00033222, -0.00751978],\n",
       "        [-0.00449089, -0.01063156],\n",
       "        [-0.00888739, -0.0134681 ]]),\n",
       " array([[0.00245438, 0.        ],\n",
       "        [0.00033222, 0.        ],\n",
       "        [0.        , 0.        ],\n",
       "        [0.        , 0.        ]]),\n",
       " array([[0.07351011],\n",
       "        [0.07359045],\n",
       "        [0.07360303],\n",
       "        [0.07360303]]),\n",
       " array([[0.51836926],\n",
       "        [0.51838931],\n",
       "        [0.51839245],\n",
       "        [0.51839245]]))"
      ]
     },
     "execution_count": 3170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.forward_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 3176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00106098],\n",
       "        [0.        ]]),\n",
       " array([[0.       , 0.       ],\n",
       "        [0.0007287, 0.       ],\n",
       "        [0.       , 0.       ],\n",
       "        [0.       , 0.       ],\n",
       "        [0.       , 0.       ]]),\n",
       " array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        , -0.00116667,  0.        ,  0.        ,  0.        ]]),\n",
       " array([[-1.45825407e-06]]),\n",
       " array([[1.14443336e-06, 0.00000000e+00]]),\n",
       " array([[ 0.        , -0.00116667,  0.        ,  0.        ,  0.        ]]))"
      ]
     },
     "execution_count": 3177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.back_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial error: 0.6931368437084947\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,5) (5,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3174-a857e7533a90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3167-fb79ee86bd96>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, lr, epochs)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md_w_3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md_b_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md_w_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md_b_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md_w_3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,5) (5,2) "
     ]
    }
   ],
   "source": [
    "nn.fit(1,1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
